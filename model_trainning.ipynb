{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T12:55:15.122094Z",
     "start_time": "2020-10-09T12:55:15.098159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
      "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'],\n",
      "      dtype='object')\n",
      "----------------------------------------------------------------------\n",
      "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
      "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'target'],\n",
      "      dtype='object')\n",
      "----------------------------------------------------------------------\n",
      "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
      "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
      "       'pH', 'sulphates', 'alcohol', 'target'],\n",
      "      dtype='object')\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "\n",
    "print(heart.columns)\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "print(wine.columns)\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "print(diabetes.columns)\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T13:22:21.789274Z",
     "start_time": "2020-10-09T12:55:15.124362Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': 10, 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'lbfgs', 'verbose': False}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.91      0.67        33\n",
      "           1       0.84      0.37      0.52        43\n",
      "\n",
      "    accuracy                           0.61        76\n",
      "   macro avg       0.68      0.64      0.59        76\n",
      "weighted avg       0.70      0.61      0.58        76\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "# diabetes = pd.read_csv('data/datasets_228_482_diabetes.csv', sep = ',')\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "# wine = pd.read_csv('data/datasets_794161_1363233_wine.csv', sep = ',')\n",
    "\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "X = heart.loc[:, heart.columns != 'target']\n",
    "y = heart.target\n",
    "    \n",
    "\n",
    "tuned_parameters = [\n",
    "{'solver':['sgd'], 'hidden_layer_sizes':[10, 25, 50, 100, 150],\n",
    " 'learning_rate_init':[0.001], 'alpha':[0.0001, 0.001, 0.01, 0.1], \n",
    " 'momentum':[0.1, 0.3, 0.5, 0.7], 'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    " 'verbose':[False], 'learning_rate':['constant', 'invscaling', 'adaptive']\n",
    "},\n",
    "{'solver':['lbfgs'], 'hidden_layer_sizes':[10, 25, 50, 100, 150],\n",
    " 'learning_rate_init':[0.001], 'alpha':[0.0001, 0.001, 0.01, 0.1], \n",
    " 'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    " 'verbose':[False], 'learning_rate':['constant', 'invscaling', 'adaptive']\n",
    "},\n",
    "{'solver':['adam'], 'hidden_layer_sizes':[10, 25, 50, 100, 150],\n",
    " 'learning_rate_init':[0.001], 'alpha':[0.0001, 0.001, 0.01, 0.1], \n",
    " 'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    " 'verbose':[False], 'learning_rate':['constant', 'invscaling', 'adaptive'],\n",
    " 'epsilon':[1e-8, 1e-7, 1e-3, 1e-1]\n",
    "}\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = MLPClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/MLP_heart.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T14:34:43.626381Z",
     "start_time": "2020-10-09T13:22:21.793963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'activation': 'logistic', 'alpha': 0.1, 'epsilon': 1e-07, 'hidden_layer_sizes': 150, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam', 'verbose': False}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.79       118\n",
      "           1       0.67      0.53      0.59        74\n",
      "\n",
      "    accuracy                           0.72       192\n",
      "   macro avg       0.71      0.68      0.69       192\n",
      "weighted avg       0.71      0.72      0.71       192\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "\n",
    "\n",
    "X = wine.loc[:, wine.columns != 'target']\n",
    "y = wine.target\n",
    "    \n",
    "\n",
    "tuned_parameters = [\n",
    "{'solver':['sgd'], 'hidden_layer_sizes':[10, 25, 50, 100, 150],\n",
    " 'learning_rate_init':[0.001], 'alpha':[0.0001, 0.001, 0.01, 0.1], \n",
    " 'momentum':[0.1, 0.3, 0.5, 0.7], 'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    " 'verbose':[False], 'learning_rate':['constant', 'invscaling', 'adaptive']\n",
    "},\n",
    "{'solver':['lbfgs'], 'hidden_layer_sizes':[10, 25, 50, 100, 150],\n",
    " 'learning_rate_init':[0.001], 'alpha':[0.0001, 0.001, 0.01, 0.1], \n",
    " 'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    " 'verbose':[False], 'learning_rate':['constant', 'invscaling', 'adaptive']\n",
    "},\n",
    "{'solver':['adam'], 'hidden_layer_sizes':[10, 25, 50, 100, 150],\n",
    " 'learning_rate_init':[0.001], 'alpha':[0.0001, 0.001, 0.01, 0.1], \n",
    " 'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    " 'verbose':[False], 'learning_rate':['constant', 'invscaling', 'adaptive'],\n",
    " 'epsilon':[1e-8, 1e-7, 1e-3, 1e-1]\n",
    "}\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = MLPClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/MLP_wine.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T16:52:39.334272Z",
     "start_time": "2020-10-09T14:34:43.638925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'activation': 'logistic', 'alpha': 0.001, 'epsilon': 1e-07, 'hidden_layer_sizes': 150, 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam', 'verbose': False}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74       189\n",
      "           1       0.78      0.73      0.76       211\n",
      "\n",
      "    accuracy                           0.75       400\n",
      "   macro avg       0.75      0.75      0.75       400\n",
      "weighted avg       0.75      0.75      0.75       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "\n",
    "\n",
    "X = diabetes.loc[:, diabetes.columns != 'target']\n",
    "y = diabetes.target\n",
    "    \n",
    "\n",
    "tuned_parameters = [\n",
    "{'solver':['sgd'], 'hidden_layer_sizes':[10, 25, 50, 100, 150],\n",
    " 'learning_rate_init':[0.001], 'alpha':[0.0001, 0.001, 0.01, 0.1], \n",
    " 'momentum':[0.1, 0.3, 0.5, 0.7], 'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    " 'verbose':[False], 'learning_rate':['constant', 'invscaling', 'adaptive']\n",
    "},\n",
    "{'solver':['lbfgs'], 'hidden_layer_sizes':[10, 25, 50, 100, 150],\n",
    " 'learning_rate_init':[0.001], 'alpha':[0.0001, 0.001, 0.01, 0.1], \n",
    " 'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    " 'verbose':[False], 'learning_rate':['constant', 'invscaling', 'adaptive']\n",
    "},\n",
    "{'solver':['adam'], 'hidden_layer_sizes':[10, 25, 50, 100, 150],\n",
    " 'learning_rate_init':[0.001], 'alpha':[0.0001, 0.001, 0.01, 0.1], \n",
    " 'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    " 'verbose':[False], 'learning_rate':['constant', 'invscaling', 'adaptive'],\n",
    " 'epsilon':[1e-8, 1e-7, 1e-3, 1e-1]\n",
    "}\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = MLPClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/MLP_diabetes.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T17:39:58.614817Z",
     "start_time": "2020-10-09T16:52:39.343323Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.001, 'min_impurity_split': 0.1, 'min_samples_split': 0.1, 'oob_score': True, 'random_state': 6411994}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.76      0.81        33\n",
      "           1       0.83      0.91      0.87        43\n",
      "\n",
      "    accuracy                           0.84        76\n",
      "   macro avg       0.85      0.83      0.84        76\n",
      "weighted avg       0.84      0.84      0.84        76\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "X = heart.loc[:, heart.columns != 'target']\n",
    "y = heart.target\n",
    "\n",
    "\n",
    "# n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "# min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "# min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, \n",
    "# verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)[source]\n",
    "tuned_parameters = [\n",
    "                    {'criterion':['gini'], 'random_state':[6411994], \n",
    "                     'max_depth':[10, 25, 50, 100], 'bootstrap':[True],\n",
    "                     'min_samples_split':[0.1, 0.3, 0.5, 0.7], 'max_features':['auto', 'sqrt', 'log2'],\n",
    "                     'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100], \n",
    "                     'min_impurity_split':[0.0, 0.1,0.01, 0.001, 1.0, 2.0, 5, 10, 100], 'max_leaf_nodes':[None],\n",
    "                     'oob_score':[True, False]\n",
    "                    },\n",
    "    \n",
    "                    {'criterion':['entropy'], 'random_state':[6411994], \n",
    "                     'max_depth':[10, 25, 50, 100], 'bootstrap':[True],\n",
    "                     'min_samples_split':[0.1, 0.3, 0.5, 0.7], 'max_features':['auto', 'sqrt', 'log2'],\n",
    "                     'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100], \n",
    "                     'min_impurity_split':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100], 'max_leaf_nodes':[None],\n",
    "                     'oob_score':[True, False] }\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = RandomForestClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/RF_heart.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T18:29:34.161391Z",
     "start_time": "2020-10-09T17:39:58.629461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'bootstrap': True, 'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0, 'min_impurity_split': 0, 'min_samples_split': 0.1, 'oob_score': True, 'random_state': 6411994}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79       118\n",
      "           1       0.69      0.46      0.55        74\n",
      "\n",
      "    accuracy                           0.71       192\n",
      "   macro avg       0.71      0.67      0.67       192\n",
      "weighted avg       0.71      0.71      0.70       192\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "# heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "\n",
    "\n",
    "X = wine.loc[:, wine.columns != 'target']\n",
    "y = wine.target\n",
    "\n",
    "# n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "# min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "# min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, \n",
    "# verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)[source]\n",
    "tuned_parameters = [\n",
    "                    {'criterion':['gini'], 'random_state':[6411994], \n",
    "                     'max_depth':[10, 25, 50, 100], 'bootstrap':[True],\n",
    "                     'min_samples_split':[0.1, 0.3, 0.5, 0.7], 'max_features':['auto', 'sqrt', 'log2'],\n",
    "                     'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100], \n",
    "                     'min_impurity_split':[0.0, 0.1,0.01, 0.001, 1.0, 2.0, 5, 10, 100], 'max_leaf_nodes':[None],\n",
    "                     'oob_score':[True, False]\n",
    "                    },\n",
    "    \n",
    "                    {'criterion':['entropy'], 'random_state':[6411994], \n",
    "                     'max_depth':[10, 25, 50, 100], 'bootstrap':[True],\n",
    "                     'min_samples_split':[0.1, 0.3, 0.5, 0.7], 'max_features':['auto', 'sqrt', 'log2'],\n",
    "                     'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100], \n",
    "                     'min_impurity_split':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100], 'max_leaf_nodes':[None],\n",
    "                     'oob_score':[True, False] }\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = RandomForestClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/RF_wine.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T19:20:55.391072Z",
     "start_time": "2020-10-09T18:29:34.171670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0, 'min_impurity_split': 0.0, 'min_samples_split': 0.1, 'oob_score': True, 'random_state': 6411994}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72       189\n",
      "           1       0.74      0.79      0.77       211\n",
      "\n",
      "    accuracy                           0.74       400\n",
      "   macro avg       0.75      0.74      0.74       400\n",
      "weighted avg       0.75      0.74      0.74       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "X = diabetes.loc[:, diabetes.columns != 'target']\n",
    "y = diabetes.target\n",
    "\n",
    "\n",
    "# n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "# min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "# min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, \n",
    "# verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)[source]\n",
    "tuned_parameters = [\n",
    "                    {'criterion':['gini'], 'random_state':[6411994], \n",
    "                     'max_depth':[10, 25, 50, 100], 'bootstrap':[True],\n",
    "                     'min_samples_split':[0.1, 0.3, 0.5, 0.7], 'max_features':['auto', 'sqrt', 'log2'],\n",
    "                     'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100], \n",
    "                     'min_impurity_split':[0.0, 0.1,0.01, 0.001, 1.0, 2.0, 5, 10, 100], 'max_leaf_nodes':[None],\n",
    "                     'oob_score':[True, False]\n",
    "                    },\n",
    "    \n",
    "                    {'criterion':['entropy'], 'random_state':[6411994], \n",
    "                     'max_depth':[10, 25, 50, 100], 'bootstrap':[True],\n",
    "                     'min_samples_split':[0.1, 0.3, 0.5, 0.7], 'max_features':['auto', 'sqrt', 'log2'],\n",
    "                     'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100], \n",
    "                     'min_impurity_split':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100], 'max_leaf_nodes':[None],\n",
    "                     'oob_score':[True, False] }\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = RandomForestClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/RF_diabetes.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T19:20:55.598507Z",
     "start_time": "2020-10-09T19:20:55.412292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'var_smoothing': 1e-09}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90        33\n",
      "           1       0.93      0.91      0.92        43\n",
      "\n",
      "    accuracy                           0.91        76\n",
      "   macro avg       0.91      0.91      0.91        76\n",
      "weighted avg       0.91      0.91      0.91        76\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "\n",
    "X = heart.loc[:, heart.columns != 'target']\n",
    "y = heart.target\n",
    "\n",
    "\n",
    "tuned_parameters = [\n",
    "                    {'var_smoothing':[1e-9, 1e-3, 1e-4]}\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = GaussianNB())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/NaiveBayes_heart.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T19:20:55.737499Z",
     "start_time": "2020-10-09T19:20:55.601703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'var_smoothing': 1e-09}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.81      0.77       118\n",
      "           1       0.63      0.53      0.57        74\n",
      "\n",
      "    accuracy                           0.70       192\n",
      "   macro avg       0.68      0.67      0.67       192\n",
      "weighted avg       0.69      0.70      0.69       192\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "# heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "\n",
    "X = wine.loc[:, wine.columns != 'target']\n",
    "y = wine.target\n",
    "\n",
    "\n",
    "tuned_parameters = [\n",
    "                    {'var_smoothing':[1e-9, 1e-3, 1e-4]}\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = GaussianNB())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/NaiveBayes_wine.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T19:20:55.868548Z",
     "start_time": "2020-10-09T19:20:55.739306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'var_smoothing': 1e-09}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72       189\n",
      "           1       0.74      0.78      0.76       211\n",
      "\n",
      "    accuracy                           0.74       400\n",
      "   macro avg       0.74      0.74      0.74       400\n",
      "weighted avg       0.74      0.74      0.74       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "\n",
    "X = diabetes.loc[:, diabetes.columns != 'target']\n",
    "y = diabetes.target\n",
    "\n",
    "\n",
    "tuned_parameters = [\n",
    "                    {'var_smoothing':[1e-9, 1e-3, 1e-4]}\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = GaussianNB())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/NaiveBayes_diabetes.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### base classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T19:20:56.380750Z",
     "start_time": "2020-10-09T19:20:55.870600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     real_label  pred_label mat_conf_mod\n",
      "113           1           0           FN\n",
      "267           0           1           FP\n",
      "168           0           0           TN\n",
      "154           1           1           TP\n",
      "Int64Index([113, 267, 168, 154], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#my svm to be explained\n",
    "model = serializer.load_model(file_name = 'serialized_model/DT_heart.pkl')\n",
    "\n",
    "predictors = heart.loc[:, heart.columns != 'target']\n",
    "target = heart.target    \n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, \n",
    "                                                    target, \n",
    "                                                    test_size = 0.25, \n",
    "                                                    random_state = 6411994)\n",
    "\n",
    "\n",
    "\n",
    "predicoes = model.predict(X_test)\n",
    "saida = pd.DataFrame(index = y_test.index)\n",
    "\n",
    "saida['real_label'] = y_test\n",
    "saida['pred_label'] = predicoes\n",
    "saida['mat_conf_mod'] = np.select([\n",
    "                                    ((saida['real_label'] == 1) & (saida['pred_label'] == 1)),\n",
    "                                    ((saida['real_label'] == 0) & (saida['pred_label'] == 1)), \n",
    "                                    ((saida['real_label'] == 0) & (saida['pred_label'] == 0)), \n",
    "                                    ((saida['real_label'] == 1) & (saida['pred_label'] == 0)) \n",
    "                                  ], \n",
    "                                  [\n",
    "                                    'TP',\n",
    "                                    'FP',\n",
    "                                    'TN',\n",
    "                                    'FN'\n",
    "                                  ], \n",
    "                                    default='Unknown'\n",
    "                                )\n",
    "\n",
    "\n",
    "#random sample by each possible value of confusion matrix\n",
    "grouped_data = saida.groupby(['mat_conf_mod'])\n",
    "sample_by_group = grouped_data.sample(n = 1, random_state = 6411994)\n",
    "\n",
    "print(sample_by_group)\n",
    "print(sample_by_group.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T19:20:56.396463Z",
     "start_time": "2020-10-09T19:20:56.383641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = [1, 0, 1, 0, 0, 1]\n",
    "y_pred = [0, 0, 1, 1, 0, 0]\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "print(tn)\n",
    "print(fp)\n",
    "print(fn)\n",
    "print(tp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T19:29:25.300225Z",
     "start_time": "2020-10-09T19:20:56.398963Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'min_impurity_decrease': 0.01, 'min_impurity_split': 0.0, 'min_samples_leaf': 5, 'min_samples_split': 8, 'splitter': 'best'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75        33\n",
      "           1       0.81      0.79      0.80        43\n",
      "\n",
      "    accuracy                           0.78        76\n",
      "   macro avg       0.77      0.77      0.77        76\n",
      "weighted avg       0.78      0.78      0.78        76\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "X = heart.loc[:, heart.columns != 'target']\n",
    "y = heart.target\n",
    "\n",
    "\n",
    "tuned_parameters = [\n",
    "{'criterion':['gini'], 'splitter':['best', 'random'], 'max_features':['auto', 'sqrt', 'log2'],\n",
    " 'max_depth':[None], 'min_samples_split':[2, 4, 8, 10], 'min_samples_leaf':[1, 5, 10, 15],\n",
    " 'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100],\n",
    " 'min_impurity_split':[0.0, 0.1,0.01, 0.001, 1.0, 2.0, 5, 10, 100]},\n",
    "{'criterion':['entropy'], 'splitter':['best', 'random'], 'max_features':['auto', 'sqrt', 'log2'],\n",
    " 'max_depth':[None], 'min_samples_split':[2, 4, 8, 10], 'min_samples_leaf':[1, 5, 10, 15],\n",
    " 'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100],\n",
    " 'min_impurity_split':[0.0, 0.1,0.01, 0.001, 1.0, 2.0, 5, 10, 100]}\n",
    "]\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = tree.DecisionTreeClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/DT_heart.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T19:38:09.462017Z",
     "start_time": "2020-10-09T19:29:25.303122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'min_impurity_decrease': 0, 'min_impurity_split': 0.1, 'min_samples_leaf': 15, 'min_samples_split': 8, 'splitter': 'best'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80       118\n",
      "           1       0.70      0.58      0.64        74\n",
      "\n",
      "    accuracy                           0.74       192\n",
      "   macro avg       0.73      0.71      0.72       192\n",
      "weighted avg       0.74      0.74      0.74       192\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "# heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn import tree\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "\n",
    "X = wine.loc[:, wine.columns != 'target']\n",
    "y = wine.target\n",
    "\n",
    "tuned_parameters = [\n",
    "{'criterion':['gini'], 'splitter':['best', 'random'], 'max_features':['auto', 'sqrt', 'log2'],\n",
    " 'max_depth':[None], 'min_samples_split':[2, 4, 8, 10], 'min_samples_leaf':[1, 5, 10, 15],\n",
    " 'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100],\n",
    " 'min_impurity_split':[0.0, 0.1,0.01, 0.001, 1.0, 2.0, 5, 10, 100]},\n",
    "{'criterion':['entropy'], 'splitter':['best', 'random'], 'max_features':['auto', 'sqrt', 'log2'],\n",
    " 'max_depth':[None], 'min_samples_split':[2, 4, 8, 10], 'min_samples_leaf':[1, 5, 10, 15],\n",
    " 'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100],\n",
    " 'min_impurity_split':[0.0, 0.1,0.01, 0.001, 1.0, 2.0, 5, 10, 100]}\n",
    "]\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = tree.DecisionTreeClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/DT_wine.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T11:41:28.351639Z",
     "start_time": "2020-08-13T11:41:28.310321Z"
    }
   },
   "source": [
    "### diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T19:47:01.896982Z",
     "start_time": "2020-10-09T19:38:09.465937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'min_impurity_decrease': 0.001, 'min_impurity_split': 0.1, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75       189\n",
      "           1       0.77      0.79      0.78       211\n",
      "\n",
      "    accuracy                           0.76       400\n",
      "   macro avg       0.76      0.76      0.76       400\n",
      "weighted avg       0.76      0.76      0.76       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "# heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "\n",
    "X = diabetes.loc[:, diabetes.columns != 'target']\n",
    "y = diabetes.target\n",
    "\n",
    "\n",
    "\n",
    "tuned_parameters = [\n",
    "{'criterion':['gini'], 'splitter':['best', 'random'], 'max_features':['auto', 'sqrt', 'log2'],\n",
    " 'max_depth':[None], 'min_samples_split':[2, 4, 8, 10], 'min_samples_leaf':[1, 5, 10, 15],\n",
    " 'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100],\n",
    " 'min_impurity_split':[0.0, 0.1,0.01, 0.001, 1.0, 2.0, 5, 10, 100]},\n",
    "{'criterion':['entropy'], 'splitter':['best', 'random'], 'max_features':['auto', 'sqrt', 'log2'],\n",
    " 'max_depth':[None], 'min_samples_split':[2, 4, 8, 10], 'min_samples_leaf':[1, 5, 10, 15],\n",
    " 'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100],\n",
    " 'min_impurity_split':[0.0, 0.1,0.01, 0.001, 1.0, 2.0, 5, 10, 100]}\n",
    "]\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = tree.DecisionTreeClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/DT_diabetes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T17:21:53.119935Z",
     "start_time": "2020-10-10T17:21:36.707465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 10, 'metric': 'manhattan', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73        33\n",
      "           1       0.79      0.79      0.79        43\n",
      "\n",
      "    accuracy                           0.76        76\n",
      "   macro avg       0.76      0.76      0.76        76\n",
      "weighted avg       0.76      0.76      0.76        76\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn import neighbors\n",
    "\n",
    "\n",
    "\n",
    "X = heart.loc[:, heart.columns != 'target']\n",
    "y = heart.target\n",
    "\n",
    "\n",
    "tuned_parameters = [\n",
    "{'algorithm':['auto'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'weights':['uniform', 'distance'], 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean']  },\n",
    "\n",
    "{'algorithm':['ball_tree'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean'],\n",
    " 'weights':['uniform', 'distance'], 'leaf_size':[3, 10, 30, 30, 50] },\n",
    "    \n",
    "{'algorithm':['kd_tree'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean'],\n",
    " 'weights':['uniform', 'distance'], 'leaf_size':[3, 10, 30, 30, 50] },    \n",
    "    \n",
    "{'algorithm':['brute'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'weights':['uniform', 'distance'], 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean']  },\n",
    "                    ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = neighbors.KNeighborsClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/KNN_heart.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T19:47:36.290304Z",
     "start_time": "2020-10-09T19:47:17.560906Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.88      0.79       118\n",
      "           1       0.70      0.43      0.53        74\n",
      "\n",
      "    accuracy                           0.71       192\n",
      "   macro avg       0.70      0.66      0.66       192\n",
      "weighted avg       0.71      0.71      0.69       192\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn import neighbors\n",
    "\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "\n",
    "X = wine.loc[:, wine.columns != 'target']\n",
    "y = wine.target\n",
    "\n",
    "\n",
    "tuned_parameters = [\n",
    "{'algorithm':['auto'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'weights':['uniform', 'distance'], 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean']  },\n",
    "\n",
    "{'algorithm':['ball_tree'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean'],\n",
    " 'weights':['uniform', 'distance'], 'leaf_size':[3, 10, 30, 30, 50] },\n",
    "    \n",
    "{'algorithm':['kd_tree'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean'],\n",
    " 'weights':['uniform', 'distance'], 'leaf_size':[3, 10, 30, 30, 50] },    \n",
    "    \n",
    "{'algorithm':['brute'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'weights':['uniform', 'distance'], 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean']  },\n",
    "                    ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = neighbors.KNeighborsClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/KNN_wine.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T19:48:00.231985Z",
     "start_time": "2020-10-09T19:47:36.292754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 20, 'weights': 'distance'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.71      0.74       189\n",
      "           1       0.76      0.82      0.79       211\n",
      "\n",
      "    accuracy                           0.77       400\n",
      "   macro avg       0.77      0.76      0.77       400\n",
      "weighted avg       0.77      0.77      0.77       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn import neighbors\n",
    "\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "X = diabetes.loc[:, diabetes.columns != 'target']\n",
    "y = diabetes.target\n",
    "\n",
    "\n",
    "tuned_parameters = [\n",
    "{'algorithm':['auto'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'weights':['uniform', 'distance'], 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean']  },\n",
    "\n",
    "{'algorithm':['ball_tree'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean'],\n",
    " 'weights':['uniform', 'distance'], 'leaf_size':[3, 10, 30, 30, 50] },\n",
    "    \n",
    "{'algorithm':['kd_tree'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean'],\n",
    " 'weights':['uniform', 'distance'], 'leaf_size':[3, 10, 30, 30, 50] },    \n",
    "    \n",
    "{'algorithm':['brute'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'weights':['uniform', 'distance'], 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean']  },\n",
    "                    ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = neighbors.KNeighborsClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/KNN_diabetes.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T19:51:56.624059Z",
     "start_time": "2020-10-09T19:48:00.234460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 1**2 * RBF(length_scale=1), 'max_iter_predict': 100, 'n_restarts_optimizer': 50, 'optimizer': 'fmin_l_bfgs_b'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86        33\n",
      "           1       0.87      0.93      0.90        43\n",
      "\n",
      "    accuracy                           0.88        76\n",
      "   macro avg       0.88      0.87      0.88        76\n",
      "weighted avg       0.88      0.88      0.88        76\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "X = heart.loc[:, heart.columns != 'target']\n",
    "y = heart.target\n",
    "\n",
    "kernel = 1.0 * RBF(1.0)\n",
    "tuned_parameters = [\n",
    "                    {'kernel':[kernel], \n",
    "                     'optimizer': ['fmin_l_bfgs_b'], \n",
    "                     'n_restarts_optimizer':[5, 10, 50], \n",
    "                     'max_iter_predict':[100, 200]\n",
    "                    }\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = GaussianProcessClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/GaussianProcessClassifier_heart.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T20:37:55.579193Z",
     "start_time": "2020-10-09T19:51:56.628495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 1**2 * RBF(length_scale=1), 'max_iter_predict': 200, 'n_restarts_optimizer': 10, 'optimizer': 'fmin_l_bfgs_b'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79       118\n",
      "           1       0.70      0.50      0.58        74\n",
      "\n",
      "    accuracy                           0.72       192\n",
      "   macro avg       0.72      0.68      0.69       192\n",
      "weighted avg       0.72      0.72      0.71       192\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "# heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "\n",
    "X = wine.loc[:, wine.columns != 'target']\n",
    "y = wine.target\n",
    "\n",
    "kernel = 1.0 * RBF(1.0)\n",
    "tuned_parameters = [\n",
    "                    {'kernel':[kernel], \n",
    "                     'optimizer': ['fmin_l_bfgs_b'], \n",
    "                     'n_restarts_optimizer':[5, 10, 50], \n",
    "                     'max_iter_predict':[100, 200]\n",
    "                    }\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = GaussianProcessClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/GaussianProcessClassifier_wine.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T12:46:03.175512Z",
     "start_time": "2020-08-13T12:46:03.139000Z"
    }
   },
   "source": [
    "### Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T00:49:13.422999Z",
     "start_time": "2020-10-09T20:37:55.590018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 1**2 * RBF(length_scale=1), 'max_iter_predict': 100, 'n_restarts_optimizer': 50, 'optimizer': 'fmin_l_bfgs_b'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74       189\n",
      "           1       0.77      0.77      0.77       211\n",
      "\n",
      "    accuracy                           0.76       400\n",
      "   macro avg       0.75      0.75      0.75       400\n",
      "weighted avg       0.76      0.76      0.76       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "# heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "\n",
    "X = diabetes.loc[:, diabetes.columns != 'target']\n",
    "y = diabetes.target\n",
    "\n",
    "\n",
    "kernel = 1.0 * RBF(1.0)\n",
    "tuned_parameters = [\n",
    "                    {'kernel':[kernel], \n",
    "                     'optimizer': ['fmin_l_bfgs_b'], \n",
    "                     'n_restarts_optimizer':[5, 10, 50], \n",
    "                     'max_iter_predict':[100, 200]\n",
    "                    }\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = GaussianProcessClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/GaussianProcessClassifier_diabetes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T01:12:07.340734Z",
     "start_time": "2020-10-10T00:49:13.443421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100, 'kernel': 'linear', 'probability': True}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86        33\n",
      "           1       0.89      0.91      0.90        43\n",
      "\n",
      "    accuracy                           0.88        76\n",
      "   macro avg       0.88      0.88      0.88        76\n",
      "weighted avg       0.88      0.88      0.88        76\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X = heart.loc[:, heart.columns != 'target']\n",
    "y = heart.target\n",
    "    \n",
    "tuned_parameters = [\n",
    "                    #kernel rbf\n",
    "                    {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [1, 10, 100, 1000], 'probability':[True]},\n",
    "                    #kernel linear \n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000], 'probability':[True]}\n",
    "                    #kernel sigmoid\n",
    "#                     {'kernel': ['sigmoid'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000], \n",
    "#                      'coef0':[1e-3, 1e-4, 0, 1.0, 2.0, 10], 'probability':[True]},\n",
    "#                     #kernel poly\n",
    "#                     {'kernel': ['poly'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000] , \n",
    "#                      'degree':[1,2,3,4], 'coef0':[1e-3, 1e-4, 0, 1.0, 2.0, 10], 'probability':[True]}                    \n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X, \n",
    "                                target = y, \n",
    "                                folds = 10, \n",
    "                                param_to_be_tunned = tuned_parameters, \n",
    "                                estimator = SVC())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/svm_heart.pkl')\n",
    "\n",
    "# Tuning hyper-parameters for f1\n",
    "# Best parameters set found on development set:\n",
    "# {'C': 1, 'coef0': 0.001, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T15:00:47.656308Z",
     "start_time": "2020-10-10T12:59:47.468839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'kernel': 'linear', 'probability': True}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79       118\n",
      "           1       0.68      0.55      0.61        74\n",
      "\n",
      "    accuracy                           0.73       192\n",
      "   macro avg       0.72      0.70      0.70       192\n",
      "weighted avg       0.72      0.73      0.72       192\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "\n",
    "X = wine.loc[:, wine.columns != 'target']\n",
    "y = wine.target\n",
    "    \n",
    "tuned_parameters = [\n",
    "                    #kernel rbf\n",
    "                    {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [1, 10, 100, 1000], 'probability':[True]},\n",
    "                    #kernel linear \n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000], 'probability':[True]}\n",
    "                    #kernel sigmoid\n",
    "#                     {'kernel': ['sigmoid'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000], \n",
    "#                      'coef0':[1e-3, 1e-4, 0, 1.0, 2.0, 10], 'probability':[True]},\n",
    "#                     #kernel poly\n",
    "#                     {'kernel': ['poly'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000] , \n",
    "#                      'degree':[1,2,3,4], 'coef0':[1e-3, 1e-4, 0, 1.0, 2.0, 10], 'probability':[True]}                    \n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X, \n",
    "                                target = y, \n",
    "                                folds = 10, \n",
    "                                param_to_be_tunned = tuned_parameters, \n",
    "                                estimator = SVC())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/svm_wine.pkl')\n",
    "\n",
    "# Tuning hyper-parameters for f1\n",
    "# Best parameters set found on development set:\n",
    "# {'C': 1, 'coef0': 0.001, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T17:16:30.678500Z",
     "start_time": "2020-10-10T15:00:47.660578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database',)).History will not be written to the database.\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf', 'probability': True}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.77      0.73       189\n",
      "           1       0.77      0.71      0.74       211\n",
      "\n",
      "    accuracy                           0.74       400\n",
      "   macro avg       0.74      0.74      0.74       400\n",
      "weighted avg       0.74      0.74      0.74       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "\n",
    "X = diabetes.loc[:, diabetes.columns != 'target']\n",
    "y = diabetes.target\n",
    "    \n",
    "tuned_parameters = [\n",
    "                    #kernel rbf\n",
    "                    {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [1, 10, 100, 1000], 'probability':[True]},\n",
    "                    #kernel linear \n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000], 'probability':[True]}\n",
    "                    #kernel sigmoid\n",
    "#                     {'kernel': ['sigmoid'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000], \n",
    "#                      'coef0':[1e-3, 1e-4, 0, 1.0, 2.0, 10], 'probability':[True]},\n",
    "#                     #kernel poly\n",
    "#                     {'kernel': ['poly'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000] , \n",
    "#                      'degree':[1,2,3,4], 'coef0':[1e-3, 1e-4, 0, 1.0, 2.0, 10], 'probability':[True]}                    \n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X, \n",
    "                                target = y, \n",
    "                                folds = 10, \n",
    "                                param_to_be_tunned = tuned_parameters, \n",
    "                                estimator = SVC())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/svm_diabetes.pkl')\n",
    "\n",
    "# Tuning hyper-parameters for f1 \n",
    "# Best parameters set found on development set:\n",
    "# {'C': 1, 'coef0': 0.001, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}b\n",
    "\n",
    "# Tuning hyper-parameters for f1\n",
    "\n",
    "# Best parameters set found on development set:\n",
    "\n",
    "# {'C': 1, 'kernel': 'linear', 'probability': True}\n",
    "# Detailed classification report:\n",
    "\n",
    "# The model is trained on the full development set.\n",
    "# The scores are computed on the full evaluation set.\n",
    "\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.75      0.78      0.76       189\n",
    "#            1       0.79      0.77      0.78       211\n",
    "\n",
    "#     accuracy                           0.77       400\n",
    "#    macro avg       0.77      0.77      0.77       400\n",
    "# weighted avg       0.77      0.77      0.77       400\n",
    "\n",
    "\n",
    "# executed in 5h 53m 26s, finished 14:16:22 2020-08-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(3.6.6 Down)",
   "language": "python",
   "name": "python366_down"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

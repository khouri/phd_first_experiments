{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T00:57:02.230820Z",
     "start_time": "2020-08-12T00:27:10.274106Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': 10, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'lbfgs', 'verbose': False}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.21      0.33        33\n",
      "           1       0.61      0.93      0.73        43\n",
      "\n",
      "    accuracy                           0.62        76\n",
      "   macro avg       0.65      0.57      0.53        76\n",
      "weighted avg       0.65      0.62      0.56        76\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "# diabetes = pd.read_csv('data/datasets_228_482_diabetes.csv', sep = ',')\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "# wine = pd.read_csv('data/datasets_794161_1363233_wine.csv', sep = ',')\n",
    "\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "X = heart.loc[:, heart.columns != 'target']\n",
    "y = heart.target\n",
    "    \n",
    "\n",
    "tuned_parameters = [\n",
    "{'solver':['sgd'], 'hidden_layer_sizes':[10, 25, 50, 100, 150],\n",
    " 'learning_rate_init':[0.001], 'alpha':[0.0001, 0.001, 0.01, 0.1], \n",
    " 'momentum':[0.1, 0.3, 0.5, 0.7], 'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    " 'verbose':[False], 'learning_rate':['constant', 'invscaling', 'adaptive']\n",
    "},\n",
    "{'solver':['lbfgs'], 'hidden_layer_sizes':[10, 25, 50, 100, 150],\n",
    " 'learning_rate_init':[0.001], 'alpha':[0.0001, 0.001, 0.01, 0.1], \n",
    " 'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    " 'verbose':[False], 'learning_rate':['constant', 'invscaling', 'adaptive']\n",
    "},\n",
    "{'solver':['adam'], 'hidden_layer_sizes':[10, 25, 50, 100, 150],\n",
    " 'learning_rate_init':[0.001], 'alpha':[0.0001, 0.001, 0.01, 0.1], \n",
    " 'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    " 'verbose':[False], 'learning_rate':['constant', 'invscaling', 'adaptive'],\n",
    " 'epsilon':[1e-8, 1e-7, 1e-3, 1e-1]\n",
    "}\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = MLPClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/MLP_heart.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T22:15:02.998523Z",
     "start_time": "2020-08-12T20:55:48.294611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'activation': 'logistic', 'alpha': 0.001, 'epsilon': 1e-08, 'hidden_layer_sizes': 150, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam', 'verbose': False}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.87      0.79       118\n",
      "           1       0.70      0.47      0.56        74\n",
      "\n",
      "    accuracy                           0.72       192\n",
      "   macro avg       0.71      0.67      0.68       192\n",
      "weighted avg       0.72      0.72      0.70       192\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "\n",
    "\n",
    "X = wine.loc[:, wine.columns != 'target']\n",
    "y = wine.target\n",
    "    \n",
    "\n",
    "tuned_parameters = [\n",
    "{'solver':['sgd'], 'hidden_layer_sizes':[10, 25, 50, 100, 150],\n",
    " 'learning_rate_init':[0.001], 'alpha':[0.0001, 0.001, 0.01, 0.1], \n",
    " 'momentum':[0.1, 0.3, 0.5, 0.7], 'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    " 'verbose':[False], 'learning_rate':['constant', 'invscaling', 'adaptive']\n",
    "},\n",
    "{'solver':['lbfgs'], 'hidden_layer_sizes':[10, 25, 50, 100, 150],\n",
    " 'learning_rate_init':[0.001], 'alpha':[0.0001, 0.001, 0.01, 0.1], \n",
    " 'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    " 'verbose':[False], 'learning_rate':['constant', 'invscaling', 'adaptive']\n",
    "},\n",
    "{'solver':['adam'], 'hidden_layer_sizes':[10, 25, 50, 100, 150],\n",
    " 'learning_rate_init':[0.001], 'alpha':[0.0001, 0.001, 0.01, 0.1], \n",
    " 'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    " 'verbose':[False], 'learning_rate':['constant', 'invscaling', 'adaptive'],\n",
    " 'epsilon':[1e-8, 1e-7, 1e-3, 1e-1]\n",
    "}\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = MLPClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/MLP_wine.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T23:53:21.562793Z",
     "start_time": "2020-08-12T22:16:46.125285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'activation': 'logistic', 'alpha': 0.01, 'epsilon': 1e-07, 'hidden_layer_sizes': 100, 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam', 'verbose': False}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67       189\n",
      "           1       0.70      0.74      0.72       211\n",
      "\n",
      "    accuracy                           0.69       400\n",
      "   macro avg       0.69      0.69      0.69       400\n",
      "weighted avg       0.69      0.69      0.69       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "\n",
    "\n",
    "X = diabetes.loc[:, diabetes.columns != 'target']\n",
    "y = diabetes.target\n",
    "    \n",
    "\n",
    "tuned_parameters = [\n",
    "{'solver':['sgd'], 'hidden_layer_sizes':[10, 25, 50, 100, 150],\n",
    " 'learning_rate_init':[0.001], 'alpha':[0.0001, 0.001, 0.01, 0.1], \n",
    " 'momentum':[0.1, 0.3, 0.5, 0.7], 'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    " 'verbose':[False], 'learning_rate':['constant', 'invscaling', 'adaptive']\n",
    "},\n",
    "{'solver':['lbfgs'], 'hidden_layer_sizes':[10, 25, 50, 100, 150],\n",
    " 'learning_rate_init':[0.001], 'alpha':[0.0001, 0.001, 0.01, 0.1], \n",
    " 'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    " 'verbose':[False], 'learning_rate':['constant', 'invscaling', 'adaptive']\n",
    "},\n",
    "{'solver':['adam'], 'hidden_layer_sizes':[10, 25, 50, 100, 150],\n",
    " 'learning_rate_init':[0.001], 'alpha':[0.0001, 0.001, 0.01, 0.1], \n",
    " 'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    " 'verbose':[False], 'learning_rate':['constant', 'invscaling', 'adaptive'],\n",
    " 'epsilon':[1e-8, 1e-7, 1e-3, 1e-1]\n",
    "}\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = MLPClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/MLP_diabetes.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T22:58:20.093086Z",
     "start_time": "2020-08-11T22:28:11.182052Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.001, 'min_impurity_split': 0.1, 'min_samples_split': 0.1, 'oob_score': True, 'random_state': 6411994}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.76      0.81        33\n",
      "           1       0.83      0.91      0.87        43\n",
      "\n",
      "    accuracy                           0.84        76\n",
      "   macro avg       0.85      0.83      0.84        76\n",
      "weighted avg       0.84      0.84      0.84        76\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "X = heart.loc[:, heart.columns != 'target']\n",
    "y = heart.target\n",
    "\n",
    "\n",
    "# n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "# min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "# min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, \n",
    "# verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)[source]\n",
    "tuned_parameters = [\n",
    "                    {'criterion':['gini'], 'random_state':[6411994], \n",
    "                     'max_depth':[10, 25, 50, 100], 'bootstrap':[True],\n",
    "                     'min_samples_split':[0.1, 0.3, 0.5, 0.7], 'max_features':['auto', 'sqrt', 'log2'],\n",
    "                     'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100], \n",
    "                     'min_impurity_split':[0.0, 0.1,0.01, 0.001, 1.0, 2.0, 5, 10, 100], 'max_leaf_nodes':[None],\n",
    "                     'oob_score':[True, False]\n",
    "                    },\n",
    "    \n",
    "                    {'criterion':['entropy'], 'random_state':[6411994], \n",
    "                     'max_depth':[10, 25, 50, 100], 'bootstrap':[True],\n",
    "                     'min_samples_split':[0.1, 0.3, 0.5, 0.7], 'max_features':['auto', 'sqrt', 'log2'],\n",
    "                     'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100], \n",
    "                     'min_impurity_split':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100], 'max_leaf_nodes':[None],\n",
    "                     'oob_score':[True, False] }\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = RandomForestClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/RF_heart.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T00:33:02.935126Z",
     "start_time": "2020-08-12T23:58:23.510545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'bootstrap': True, 'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0, 'min_impurity_split': 0, 'min_samples_split': 0.1, 'oob_score': True, 'random_state': 6411994}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.91      0.81       118\n",
      "           1       0.76      0.46      0.57        74\n",
      "\n",
      "    accuracy                           0.73       192\n",
      "   macro avg       0.74      0.68      0.69       192\n",
      "weighted avg       0.74      0.73      0.72       192\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "# heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "\n",
    "\n",
    "X = wine.loc[:, wine.columns != 'target']\n",
    "y = wine.target\n",
    "\n",
    "# n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "# min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "# min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, \n",
    "# verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)[source]\n",
    "tuned_parameters = [\n",
    "                    {'criterion':['gini'], 'random_state':[6411994], \n",
    "                     'max_depth':[10, 25, 50, 100], 'bootstrap':[True],\n",
    "                     'min_samples_split':[0.1, 0.3, 0.5, 0.7], 'max_features':['auto', 'sqrt', 'log2'],\n",
    "                     'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100], \n",
    "                     'min_impurity_split':[0.0, 0.1,0.01, 0.001, 1.0, 2.0, 5, 10, 100], 'max_leaf_nodes':[None],\n",
    "                     'oob_score':[True, False]\n",
    "                    },\n",
    "    \n",
    "                    {'criterion':['entropy'], 'random_state':[6411994], \n",
    "                     'max_depth':[10, 25, 50, 100], 'bootstrap':[True],\n",
    "                     'min_samples_split':[0.1, 0.3, 0.5, 0.7], 'max_features':['auto', 'sqrt', 'log2'],\n",
    "                     'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100], \n",
    "                     'min_impurity_split':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100], 'max_leaf_nodes':[None],\n",
    "                     'oob_score':[True, False] }\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = RandomForestClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/RF_wine.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T01:12:25.856723Z",
     "start_time": "2020-08-13T00:33:02.938612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'bootstrap': True, 'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0, 'min_impurity_split': 0, 'min_samples_split': 0.1, 'oob_score': True, 'random_state': 6411994}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.68      0.70       189\n",
      "           1       0.73      0.78      0.75       211\n",
      "\n",
      "    accuracy                           0.73       400\n",
      "   macro avg       0.73      0.73      0.73       400\n",
      "weighted avg       0.73      0.73      0.73       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "X = diabetes.loc[:, diabetes.columns != 'target']\n",
    "y = diabetes.target\n",
    "\n",
    "\n",
    "# n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "# min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "# min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, \n",
    "# verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)[source]\n",
    "tuned_parameters = [\n",
    "                    {'criterion':['gini'], 'random_state':[6411994], \n",
    "                     'max_depth':[10, 25, 50, 100], 'bootstrap':[True],\n",
    "                     'min_samples_split':[0.1, 0.3, 0.5, 0.7], 'max_features':['auto', 'sqrt', 'log2'],\n",
    "                     'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100], \n",
    "                     'min_impurity_split':[0.0, 0.1,0.01, 0.001, 1.0, 2.0, 5, 10, 100], 'max_leaf_nodes':[None],\n",
    "                     'oob_score':[True, False]\n",
    "                    },\n",
    "    \n",
    "                    {'criterion':['entropy'], 'random_state':[6411994], \n",
    "                     'max_depth':[10, 25, 50, 100], 'bootstrap':[True],\n",
    "                     'min_samples_split':[0.1, 0.3, 0.5, 0.7], 'max_features':['auto', 'sqrt', 'log2'],\n",
    "                     'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100], \n",
    "                     'min_impurity_split':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100], 'max_leaf_nodes':[None],\n",
    "                     'oob_score':[True, False] }\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = RandomForestClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/RF_diabetes.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:26:33.141662Z",
     "start_time": "2020-08-09T22:26:32.956334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'var_smoothing': 1e-09}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.775 (+/-0.199) for {'var_smoothing': 1e-09}\n",
      "0.710 (+/-0.115) for {'var_smoothing': 0.001}\n",
      "0.763 (+/-0.130) for {'var_smoothing': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90        33\n",
      "           1       0.93      0.91      0.92        43\n",
      "\n",
      "    accuracy                           0.91        76\n",
      "   macro avg       0.91      0.91      0.91        76\n",
      "weighted avg       0.91      0.91      0.91        76\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "\n",
    "X = heart.loc[:, heart.columns != 'target']\n",
    "y = heart.target\n",
    "\n",
    "\n",
    "tuned_parameters = [\n",
    "                    {'var_smoothing':[1e-9, 1e-3, 1e-4]}\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = GaussianNB())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/NaiveBayes_heart.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T02:05:32.349039Z",
     "start_time": "2020-08-13T02:05:32.026875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'var_smoothing': 1e-09}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.80      0.76       118\n",
      "           1       0.61      0.51      0.56        74\n",
      "\n",
      "    accuracy                           0.69       192\n",
      "   macro avg       0.67      0.66      0.66       192\n",
      "weighted avg       0.68      0.69      0.68       192\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "# heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "\n",
    "X = wine.loc[:, wine.columns != 'target']\n",
    "y = wine.target\n",
    "\n",
    "\n",
    "tuned_parameters = [\n",
    "                    {'var_smoothing':[1e-9, 1e-3, 1e-4]}\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = GaussianNB())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/NaiveBayes_wine.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T02:05:39.773400Z",
     "start_time": "2020-08-13T02:05:39.610900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'var_smoothing': 1e-09}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.68      0.70       189\n",
      "           1       0.73      0.78      0.75       211\n",
      "\n",
      "    accuracy                           0.73       400\n",
      "   macro avg       0.73      0.73      0.73       400\n",
      "weighted avg       0.73      0.73      0.73       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "\n",
    "X = diabetes.loc[:, diabetes.columns != 'target']\n",
    "y = diabetes.target\n",
    "\n",
    "\n",
    "tuned_parameters = [\n",
    "                    {'var_smoothing':[1e-9, 1e-3, 1e-4]}\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = GaussianNB())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/NaiveBayes_diabetes.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### base classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T21:31:16.514813Z",
     "start_time": "2020-10-07T21:31:16.053635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     real_label  pred_label mat_conf_mod\n",
      "113           1           0           FN\n",
      "267           0           1           FP\n",
      "168           0           0           TN\n",
      "154           1           1           TP\n",
      "Int64Index([113, 267, 168, 154], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#my svm to be explained\n",
    "model = serializer.load_model(file_name = 'serialized_model/DT_heart.pkl')\n",
    "\n",
    "predictors = heart.loc[:, heart.columns != 'target']\n",
    "target = heart.target    \n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, \n",
    "                                                    target, \n",
    "                                                    test_size = 0.25, \n",
    "                                                    random_state = 6411994)\n",
    "\n",
    "\n",
    "\n",
    "predicoes = model.predict(X_test)\n",
    "saida = pd.DataFrame(index = y_test.index)\n",
    "\n",
    "saida['real_label'] = y_test\n",
    "saida['pred_label'] = predicoes\n",
    "saida['mat_conf_mod'] = np.select([\n",
    "                                    ((saida['real_label'] == 1) & (saida['pred_label'] == 1)),\n",
    "                                    ((saida['real_label'] == 0) & (saida['pred_label'] == 1)), \n",
    "                                    ((saida['real_label'] == 0) & (saida['pred_label'] == 0)), \n",
    "                                    ((saida['real_label'] == 1) & (saida['pred_label'] == 0)) \n",
    "                                  ], \n",
    "                                  [\n",
    "                                    'TP',\n",
    "                                    'FP',\n",
    "                                    'TN',\n",
    "                                    'FN'\n",
    "                                  ], \n",
    "                                    default='Unknown'\n",
    "                                )\n",
    "\n",
    "\n",
    "#random sample by each possible value of confusion matrix\n",
    "grouped_data = saida.groupby(['mat_conf_mod'])\n",
    "sample_by_group = grouped_data.sample(n = 1, random_state = 6411994)\n",
    "\n",
    "print(sample_by_group)\n",
    "print(sample_by_group.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T19:48:34.281537Z",
     "start_time": "2020-10-07T19:48:34.270890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = [1, 0, 1, 0, 0, 1]\n",
    "y_pred = [0, 0, 1, 1, 0, 0]\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "print(tn)\n",
    "print(fp)\n",
    "print(fn)\n",
    "print(tp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T00:06:05.537118Z",
     "start_time": "2020-08-11T23:55:02.002638Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_impurity_decrease': 0, 'min_impurity_split': 0.1, 'min_samples_leaf': 5, 'min_samples_split': 8, 'splitter': 'best'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77        33\n",
      "           1       0.86      0.72      0.78        43\n",
      "\n",
      "    accuracy                           0.78        76\n",
      "   macro avg       0.78      0.78      0.78        76\n",
      "weighted avg       0.79      0.78      0.78        76\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "X = heart.loc[:, heart.columns != 'target']\n",
    "y = heart.target\n",
    "\n",
    "\n",
    "tuned_parameters = [\n",
    "{'criterion':['gini'], 'splitter':['best', 'random'], 'max_features':['auto', 'sqrt', 'log2'],\n",
    " 'max_depth':[None], 'min_samples_split':[2, 4, 8, 10], 'min_samples_leaf':[1, 5, 10, 15],\n",
    " 'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100],\n",
    " 'min_impurity_split':[0.0, 0.1,0.01, 0.001, 1.0, 2.0, 5, 10, 100]},\n",
    "{'criterion':['entropy'], 'splitter':['best', 'random'], 'max_features':['auto', 'sqrt', 'log2'],\n",
    " 'max_depth':[None], 'min_samples_split':[2, 4, 8, 10], 'min_samples_leaf':[1, 5, 10, 15],\n",
    " 'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100],\n",
    " 'min_impurity_split':[0.0, 0.1,0.01, 0.001, 1.0, 2.0, 5, 10, 100]}\n",
    "]\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = tree.DecisionTreeClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/DT_heart.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T12:14:16.216386Z",
     "start_time": "2020-08-13T11:58:25.830315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'min_impurity_decrease': 0, 'min_impurity_split': 0.1, 'min_samples_leaf': 15, 'min_samples_split': 8, 'splitter': 'best'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       118\n",
      "           1       0.62      0.59      0.61        74\n",
      "\n",
      "    accuracy                           0.70       192\n",
      "   macro avg       0.69      0.68      0.68       192\n",
      "weighted avg       0.70      0.70      0.70       192\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "# heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn import tree\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "\n",
    "X = wine.loc[:, wine.columns != 'target']\n",
    "y = wine.target\n",
    "\n",
    "tuned_parameters = [\n",
    "{'criterion':['gini'], 'splitter':['best', 'random'], 'max_features':['auto', 'sqrt', 'log2'],\n",
    " 'max_depth':[None], 'min_samples_split':[2, 4, 8, 10], 'min_samples_leaf':[1, 5, 10, 15],\n",
    " 'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100],\n",
    " 'min_impurity_split':[0.0, 0.1,0.01, 0.001, 1.0, 2.0, 5, 10, 100]},\n",
    "{'criterion':['entropy'], 'splitter':['best', 'random'], 'max_features':['auto', 'sqrt', 'log2'],\n",
    " 'max_depth':[None], 'min_samples_split':[2, 4, 8, 10], 'min_samples_leaf':[1, 5, 10, 15],\n",
    " 'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100],\n",
    " 'min_impurity_split':[0.0, 0.1,0.01, 0.001, 1.0, 2.0, 5, 10, 100]}\n",
    "]\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = tree.DecisionTreeClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/DT_wine.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T11:41:28.351639Z",
     "start_time": "2020-08-13T11:41:28.310321Z"
    }
   },
   "source": [
    "### diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T12:35:37.693427Z",
     "start_time": "2020-08-13T12:14:16.226167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'min_impurity_decrease': 0.001, 'min_impurity_split': 0.1, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.71      0.71       189\n",
      "           1       0.74      0.73      0.74       211\n",
      "\n",
      "    accuracy                           0.72       400\n",
      "   macro avg       0.72      0.72      0.72       400\n",
      "weighted avg       0.72      0.72      0.72       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "# heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "\n",
    "X = diabetes.loc[:, diabetes.columns != 'target']\n",
    "y = diabetes.target\n",
    "\n",
    "\n",
    "\n",
    "tuned_parameters = [\n",
    "{'criterion':['gini'], 'splitter':['best', 'random'], 'max_features':['auto', 'sqrt', 'log2'],\n",
    " 'max_depth':[None], 'min_samples_split':[2, 4, 8, 10], 'min_samples_leaf':[1, 5, 10, 15],\n",
    " 'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100],\n",
    " 'min_impurity_split':[0.0, 0.1,0.01, 0.001, 1.0, 2.0, 5, 10, 100]},\n",
    "{'criterion':['entropy'], 'splitter':['best', 'random'], 'max_features':['auto', 'sqrt', 'log2'],\n",
    " 'max_depth':[None], 'min_samples_split':[2, 4, 8, 10], 'min_samples_leaf':[1, 5, 10, 15],\n",
    " 'min_impurity_decrease':[0, 0.1,0.01, 0.001, 1, 2, 5, 10, 100],\n",
    " 'min_impurity_split':[0.0, 0.1,0.01, 0.001, 1.0, 2.0, 5, 10, 100]}\n",
    "]\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = tree.DecisionTreeClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/DT_diabetes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T00:23:13.351695Z",
     "start_time": "2020-08-12T00:22:55.682342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 10, 'metric': 'manhattan', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73        33\n",
      "           1       0.79      0.79      0.79        43\n",
      "\n",
      "    accuracy                           0.76        76\n",
      "   macro avg       0.76      0.76      0.76        76\n",
      "weighted avg       0.76      0.76      0.76        76\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn import neighbors\n",
    "\n",
    "\n",
    "\n",
    "X = heart.loc[:, heart.columns != 'target']\n",
    "y = heart.target\n",
    "\n",
    "\n",
    "tuned_parameters = [\n",
    "{'algorithm':['auto'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'weights':['uniform', 'distance'], 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean']  },\n",
    "\n",
    "{'algorithm':['ball_tree'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean'],\n",
    " 'weights':['uniform', 'distance'], 'leaf_size':[3, 10, 30, 30, 50] },\n",
    "    \n",
    "{'algorithm':['kd_tree'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean'],\n",
    " 'weights':['uniform', 'distance'], 'leaf_size':[3, 10, 30, 30, 50] },    \n",
    "    \n",
    "{'algorithm':['brute'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'weights':['uniform', 'distance'], 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean']  },\n",
    "                    ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = neighbors.KNeighborsClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/KNN_heart.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T18:21:24.701163Z",
     "start_time": "2020-10-07T18:20:49.756634Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.69       189\n",
      "           1       0.72      0.76      0.74       211\n",
      "\n",
      "    accuracy                           0.71       400\n",
      "   macro avg       0.71      0.71      0.71       400\n",
      "weighted avg       0.71      0.71      0.71       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn import neighbors\n",
    "\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "\n",
    "X = wine.loc[:, wine.columns != 'target']\n",
    "y = wine.target\n",
    "\n",
    "\n",
    "tuned_parameters = [\n",
    "{'algorithm':['auto'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'weights':['uniform', 'distance'], 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean']  },\n",
    "\n",
    "{'algorithm':['ball_tree'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean'],\n",
    " 'weights':['uniform', 'distance'], 'leaf_size':[3, 10, 30, 30, 50] },\n",
    "    \n",
    "{'algorithm':['kd_tree'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean'],\n",
    " 'weights':['uniform', 'distance'], 'leaf_size':[3, 10, 30, 30, 50] },    \n",
    "    \n",
    "{'algorithm':['brute'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'weights':['uniform', 'distance'], 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean']  },\n",
    "                    ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = neighbors.KNeighborsClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/KNN_wine.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T18:22:09.285996Z",
     "start_time": "2020-10-07T18:21:41.641339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'algorithm': 'auto', 'metric': 'chebyshev', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.84      0.76       118\n",
      "           1       0.60      0.39      0.48        74\n",
      "\n",
      "    accuracy                           0.67       192\n",
      "   macro avg       0.65      0.62      0.62       192\n",
      "weighted avg       0.66      0.67      0.65       192\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn import neighbors\n",
    "\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "X = diabetes.loc[:, diabetes.columns != 'target']\n",
    "y = diabetes.target\n",
    "\n",
    "\n",
    "tuned_parameters = [\n",
    "{'algorithm':['auto'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'weights':['uniform', 'distance'], 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean']  },\n",
    "\n",
    "{'algorithm':['ball_tree'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean'],\n",
    " 'weights':['uniform', 'distance'], 'leaf_size':[3, 10, 30, 30, 50] },\n",
    "    \n",
    "{'algorithm':['kd_tree'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean'],\n",
    " 'weights':['uniform', 'distance'], 'leaf_size':[3, 10, 30, 30, 50] },    \n",
    "    \n",
    "{'algorithm':['brute'], 'n_neighbors':[3, 5, 10, 20], \n",
    " 'weights':['uniform', 'distance'], 'metric':['minkowski', 'chebyshev', 'manhattan', 'euclidean']  },\n",
    "                    ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = neighbors.KNeighborsClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/KNN_diabetes.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T02:12:51.221899Z",
     "start_time": "2020-08-12T00:58:45.264443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 1**2 * RBF(length_scale=1), 'max_iter_predict': 100, 'n_restarts_optimizer': 50, 'optimizer': 'fmin_l_bfgs_b'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86        33\n",
      "           1       0.87      0.93      0.90        43\n",
      "\n",
      "    accuracy                           0.88        76\n",
      "   macro avg       0.88      0.87      0.88        76\n",
      "weighted avg       0.88      0.88      0.88        76\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "X = heart.loc[:, heart.columns != 'target']\n",
    "y = heart.target\n",
    "\n",
    "kernel = 1.0 * RBF(1.0)\n",
    "tuned_parameters = [\n",
    "                    {'kernel':[kernel], \n",
    "                     'optimizer': ['fmin_l_bfgs_b'], \n",
    "                     'n_restarts_optimizer':[5, 10, 50], \n",
    "                     'max_iter_predict':[100, 200]\n",
    "                    }\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = GaussianProcessClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/GaussianProcessClassifier_heart.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T00:04:47.793804Z",
     "start_time": "2020-08-13T23:42:04.198247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 1**2 * RBF(length_scale=1), 'max_iter_predict': 200, 'n_restarts_optimizer': 10, 'optimizer': 'fmin_l_bfgs_b'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.80       118\n",
      "           1       0.70      0.51      0.59        74\n",
      "\n",
      "    accuracy                           0.73       192\n",
      "   macro avg       0.72      0.69      0.70       192\n",
      "weighted avg       0.73      0.73      0.72       192\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "# heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "\n",
    "X = wine.loc[:, wine.columns != 'target']\n",
    "y = wine.target\n",
    "\n",
    "kernel = 1.0 * RBF(1.0)\n",
    "tuned_parameters = [\n",
    "                    {'kernel':[kernel], \n",
    "                     'optimizer': ['fmin_l_bfgs_b'], \n",
    "                     'n_restarts_optimizer':[5, 10, 50], \n",
    "                     'max_iter_predict':[100, 200]\n",
    "                    }\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = GaussianProcessClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/GaussianProcessClassifier_wine.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T12:46:03.175512Z",
     "start_time": "2020-08-13T12:46:03.139000Z"
    }
   },
   "source": [
    "### Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T03:52:25.218646Z",
     "start_time": "2020-08-14T00:24:08.764105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 1**2 * RBF(length_scale=1), 'max_iter_predict': 200, 'n_restarts_optimizer': 10, 'optimizer': 'fmin_l_bfgs_b'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72       189\n",
      "           1       0.75      0.77      0.76       211\n",
      "\n",
      "    accuracy                           0.74       400\n",
      "   macro avg       0.74      0.74      0.74       400\n",
      "weighted avg       0.74      0.74      0.74       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "# heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "\n",
    "X = diabetes.loc[:, diabetes.columns != 'target']\n",
    "y = diabetes.target\n",
    "\n",
    "\n",
    "kernel = 1.0 * RBF(1.0)\n",
    "tuned_parameters = [\n",
    "                    {'kernel':[kernel], \n",
    "                     'optimizer': ['fmin_l_bfgs_b'], \n",
    "                     'n_restarts_optimizer':[5, 10, 50], \n",
    "                     'max_iter_predict':[100, 200]\n",
    "                    }\n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X,\n",
    "                                target = y,\n",
    "                                folds = 10,\n",
    "                                param_to_be_tunned = tuned_parameters,\n",
    "                                estimator = GaussianProcessClassifier())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/GaussianProcessClassifier_diabetes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T17:04:52.352471Z",
     "start_time": "2020-08-17T16:43:16.061911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100, 'kernel': 'linear', 'probability': True}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86        33\n",
      "           1       0.89      0.91      0.90        43\n",
      "\n",
      "    accuracy                           0.88        76\n",
      "   macro avg       0.88      0.88      0.88        76\n",
      "weighted avg       0.88      0.88      0.88        76\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X = heart.loc[:, heart.columns != 'target']\n",
    "y = heart.target\n",
    "    \n",
    "tuned_parameters = [\n",
    "                    #kernel rbf\n",
    "                    {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [1, 10, 100, 1000], 'probability':[True]},\n",
    "                    #kernel linear \n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000], 'probability':[True]}\n",
    "                    #kernel sigmoid\n",
    "#                     {'kernel': ['sigmoid'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000], \n",
    "#                      'coef0':[1e-3, 1e-4, 0, 1.0, 2.0, 10], 'probability':[True]},\n",
    "#                     #kernel poly\n",
    "#                     {'kernel': ['poly'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000] , \n",
    "#                      'degree':[1,2,3,4], 'coef0':[1e-3, 1e-4, 0, 1.0, 2.0, 10], 'probability':[True]}                    \n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X, \n",
    "                                target = y, \n",
    "                                folds = 10, \n",
    "                                param_to_be_tunned = tuned_parameters, \n",
    "                                estimator = SVC())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/svm_heart.pkl')\n",
    "\n",
    "# Tuning hyper-parameters for f1\n",
    "# Best parameters set found on development set:\n",
    "# {'C': 1, 'coef0': 0.001, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T21:04:31.069088Z",
     "start_time": "2020-08-17T17:05:07.653183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'kernel': 'linear', 'probability': True}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.87      0.80       118\n",
      "           1       0.72      0.51      0.60        74\n",
      "\n",
      "    accuracy                           0.73       192\n",
      "   macro avg       0.73      0.69      0.70       192\n",
      "weighted avg       0.73      0.73      0.72       192\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "\n",
    "X = wine.loc[:, wine.columns != 'target']\n",
    "y = wine.target\n",
    "    \n",
    "tuned_parameters = [\n",
    "                    #kernel rbf\n",
    "                    {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [1, 10, 100, 1000], 'probability':[True]},\n",
    "                    #kernel linear \n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000], 'probability':[True]}\n",
    "                    #kernel sigmoid\n",
    "#                     {'kernel': ['sigmoid'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000], \n",
    "#                      'coef0':[1e-3, 1e-4, 0, 1.0, 2.0, 10], 'probability':[True]},\n",
    "#                     #kernel poly\n",
    "#                     {'kernel': ['poly'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000] , \n",
    "#                      'degree':[1,2,3,4], 'coef0':[1e-3, 1e-4, 0, 1.0, 2.0, 10], 'probability':[True]}                    \n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X, \n",
    "                                target = y, \n",
    "                                folds = 10, \n",
    "                                param_to_be_tunned = tuned_parameters, \n",
    "                                estimator = SVC())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/svm_wine.pkl')\n",
    "\n",
    "# Tuning hyper-parameters for f1\n",
    "# Best parameters set found on development set:\n",
    "# {'C': 1, 'coef0': 0.001, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T17:16:22.436878Z",
     "start_time": "2020-08-18T11:22:56.548063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'kernel': 'linear', 'probability': True}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76       189\n",
      "           1       0.79      0.77      0.78       211\n",
      "\n",
      "    accuracy                           0.77       400\n",
      "   macro avg       0.77      0.77      0.77       400\n",
      "weighted avg       0.77      0.77      0.77       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "\n",
    "X = diabetes.loc[:, diabetes.columns != 'target']\n",
    "y = diabetes.target\n",
    "    \n",
    "tuned_parameters = [\n",
    "                    #kernel rbf\n",
    "                    {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [1, 10, 100, 1000], 'probability':[True]},\n",
    "                    #kernel linear \n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000], 'probability':[True]}\n",
    "                    #kernel sigmoid\n",
    "#                     {'kernel': ['sigmoid'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000], \n",
    "#                      'coef0':[1e-3, 1e-4, 0, 1.0, 2.0, 10], 'probability':[True]},\n",
    "#                     #kernel poly\n",
    "#                     {'kernel': ['poly'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000] , \n",
    "#                      'degree':[1,2,3,4], 'coef0':[1e-3, 1e-4, 0, 1.0, 2.0, 10], 'probability':[True]}                    \n",
    "                   ]\n",
    "\n",
    "\n",
    "model = model_train.train_model(predictors = X, \n",
    "                                target = y, \n",
    "                                folds = 10, \n",
    "                                param_to_be_tunned = tuned_parameters, \n",
    "                                estimator = SVC())\n",
    "\n",
    "serializer.serialize_model(model = model, file_name = 'serialized_model/svm_diabetes.pkl')\n",
    "\n",
    "# Tuning hyper-parameters for f1 \n",
    "# Best parameters set found on development set:\n",
    "# {'C': 1, 'coef0': 0.001, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}b\n",
    "\n",
    "# Tuning hyper-parameters for f1\n",
    "\n",
    "# Best parameters set found on development set:\n",
    "\n",
    "# {'C': 1, 'kernel': 'linear', 'probability': True}\n",
    "# Detailed classification report:\n",
    "\n",
    "# The model is trained on the full development set.\n",
    "# The scores are computed on the full evaluation set.\n",
    "\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.75      0.78      0.76       189\n",
    "#            1       0.79      0.77      0.78       211\n",
    "\n",
    "#     accuracy                           0.77       400\n",
    "#    macro avg       0.77      0.77      0.77       400\n",
    "# weighted avg       0.77      0.77      0.77       400\n",
    "\n",
    "\n",
    "# executed in 5h 53m 26s, finished 14:16:22 2020-08-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

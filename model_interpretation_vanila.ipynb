{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The interpretations using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T12:09:52.554937Z",
     "start_time": "2020-10-09T12:09:50.134300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         float64\n",
      "sex         float64\n",
      "cp          float64\n",
      "trestbps    float64\n",
      "chol        float64\n",
      "fbs         float64\n",
      "restecg     float64\n",
      "thalach     float64\n",
      "exang       float64\n",
      "oldpeak     float64\n",
      "slope       float64\n",
      "ca          float64\n",
      "thal        float64\n",
      "target        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "import sys\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "heart = explanation.to_float(heart)\n",
    "\n",
    "print(heart.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:46:35.990489Z",
     "start_time": "2020-10-07T16:46:35.978281Z"
    }
   },
   "source": [
    "# Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T22:35:08.485986Z",
     "start_time": "2020-10-08T22:35:08.467200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed acidity           float64\n",
      "volatile acidity        float64\n",
      "citric acid             float64\n",
      "residual sugar          float64\n",
      "chlorides               float64\n",
      "free sulfur dioxide     float64\n",
      "total sulfur dioxide    float64\n",
      "density                 float64\n",
      "pH                      float64\n",
      "sulphates               float64\n",
      "alcohol                 float64\n",
      "target                    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "import sys\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "# wine.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "\n",
    "wine = explanation.to_float(wine)\n",
    "\n",
    "print(wine.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T22:35:04.507786Z",
     "start_time": "2020-10-08T22:35:04.487684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies                 float64\n",
      "Glucose                     float64\n",
      "BloodPressure               float64\n",
      "SkinThickness               float64\n",
      "Insulin                     float64\n",
      "BMI                         float64\n",
      "DiabetesPedigreeFunction    float64\n",
      "Age                         float64\n",
      "target                        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import datetime as dt\n",
    "\n",
    "import sys\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "# diabetes.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "\n",
    "diabetes = explanation.to_float(diabetes)\n",
    "\n",
    "print(diabetes.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing 4 instances (TP, FP, TN, FN) of each dataset randomly from DT to be our baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to choose 4 instances (TP, FP, TN, FN) of each dataset randomly, we have choosed the decision tree as the baseline classificator to choose the confusion matrix metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the samples from the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T22:36:42.236681Z",
     "start_time": "2020-10-08T22:36:41.782652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     real_label  pred_label mat_conf_mod\n",
      "143           1           0           FN\n",
      "203           0           1           FP\n",
      "242           0           0           TN\n",
      "96            1           1           TP\n",
      "      real_label  pred_label mat_conf_mod\n",
      "86             1           0           FN\n",
      "1458           0           1           FP\n",
      "791            0           0           TN\n",
      "1003           1           1           TP\n",
      "     real_label  pred_label mat_conf_mod\n",
      "291           1           0           FN\n",
      "725           0           1           FP\n",
      "60            0           0           TN\n",
      "755           1           1           TP\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "model = serializer.load_model(file_name = 'serialized_model/DT_heart.pkl')\n",
    "heart_sample = explanation.sample_baseline_model(model, heart)\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "model = serializer.load_model(file_name = 'serialized_model/DT_wine2.pkl')\n",
    "wine_sample = explanation.sample_baseline_model(model, wine)\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "model = serializer.load_model(file_name = 'serialized_model/DT_diabetes2.pkl')\n",
    "diabetes_sample = explanation.sample_baseline_model(model, diabetes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart dataset - explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T01:47:14.093981Z",
     "start_time": "2020-10-08T01:47:12.634326Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "heart = explanation.to_float(heart)\n",
    "\n",
    "model_file_name = 'serialized_model/MLP_heart.pkl'\n",
    "model = serializer.load_model(model_file_name)\n",
    "\n",
    "dataset = heart.copy(deep = True)\n",
    "target_names = np.array(['saud√°vel', 'doente'])\n",
    "\n",
    "folder = 'serialized_explanation/'\n",
    "model_dataset = model_file_name.replace('serialized_model/','').replace('.pkl', '').replace('_', '#').replace('_', '#')\n",
    "\n",
    "for sample in heart_sample:\n",
    "    instance_index = sample\n",
    "    num_features = dataset.columns.size - 1 #removing the target\n",
    "\n",
    "    output_file = \"\"\"{0}{1}#instance:{2}#num_features:{3}.html\"\"\".format(folder, \n",
    "                                                                          model_dataset, \n",
    "                                                                          instance_index, \n",
    "                                                                          num_features)\n",
    "#     print(output_file)\n",
    "    explanation.explain_it(model,\n",
    "                           dataset,\n",
    "                           target_names,\n",
    "                           num_features,\n",
    "                           instance_index,\n",
    "                           output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine dataset - explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T01:47:15.583400Z",
     "start_time": "2020-10-08T01:47:14.097724Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "# wine.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "wine = explanation.to_float(wine)\n",
    "\n",
    "model_file_name = 'serialized_model/MLP_wine2.pkl'\n",
    "model = serializer.load_model(model_file_name)\n",
    "\n",
    "dataset = wine.copy(deep = True)\n",
    "target_names = np.array(['ruim', 'bom'])\n",
    "\n",
    "folder = 'serialized_explanation/'\n",
    "model_dataset = model_file_name.replace('serialized_model/','').replace('.pkl', '').replace('_', '#')\n",
    "\n",
    "for sample in wine_sample:\n",
    "    instance_index = sample\n",
    "    num_features = dataset.columns.size - 1 #removing the target\n",
    "\n",
    "    output_file = \"\"\"{0}{1}#instance:{2}#num_features:{3}.html\"\"\".format(folder, \n",
    "                                                                          model_dataset, \n",
    "                                                                          instance_index, \n",
    "                                                                          num_features)\n",
    "\n",
    "\n",
    "    explanation.explain_it(model,\n",
    "                           dataset,\n",
    "                           target_names,\n",
    "                           num_features,\n",
    "                           instance_index,\n",
    "                           output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T01:47:16.780280Z",
     "start_time": "2020-10-08T01:47:15.585536Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "# diabetes.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "diabetes = explanation.to_float(diabetes)\n",
    "\n",
    "model_file_name = 'serialized_model/MLP_diabetes2.pkl'\n",
    "model = serializer.load_model(model_file_name)\n",
    "\n",
    "dataset = diabetes.copy(deep = True)\n",
    "target_names = np.array(['saud√°vel', 'doente'])\n",
    "\n",
    "folder = 'serialized_explanation/'\n",
    "model_dataset = model_file_name.replace('serialized_model/','').replace('.pkl', '').replace('_', '#')\n",
    "\n",
    "for sample in diabetes_sample:\n",
    "    instance_index = sample\n",
    "    num_features = dataset.columns.size - 1 #removing the target\n",
    "\n",
    "    output_file = \"\"\"{0}{1}#instance:{2}#num_features:{3}.html\"\"\".format(folder, \n",
    "                                                                          model_dataset, \n",
    "                                                                          instance_index, \n",
    "                                                                          num_features)\n",
    "\n",
    "\n",
    "    explanation.explain_it(model,\n",
    "                           dataset,\n",
    "                           target_names,\n",
    "                           num_features,\n",
    "                           instance_index,\n",
    "                           output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T01:47:19.212924Z",
     "start_time": "2020-10-08T01:47:16.783747Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "heart = explanation.to_float(heart)\n",
    "\n",
    "model_file_name = 'serialized_model/RF_heart.pkl'\n",
    "model = serializer.load_model(model_file_name)\n",
    "\n",
    "dataset = heart.copy(deep = True)\n",
    "target_names = np.array(['saud√°vel', 'doente'])\n",
    "\n",
    "folder = 'serialized_explanation/'\n",
    "model_dataset = model_file_name.replace('serialized_model/','').replace('.pkl', '').replace('_', '#')\n",
    "\n",
    "for sample in heart_sample:\n",
    "    instance_index = sample\n",
    "    num_features = dataset.columns.size - 1 #removing the target\n",
    "\n",
    "    output_file = \"\"\"{0}{1}#instance:{2}#num_features:{3}.html\"\"\".format(folder, \n",
    "                                                                          model_dataset, \n",
    "                                                                          instance_index, \n",
    "                                                                          num_features)\n",
    "\n",
    "    explanation.explain_it(model,\n",
    "                           dataset,\n",
    "                           target_names,\n",
    "                           num_features,\n",
    "                           instance_index,\n",
    "                           output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T01:47:21.492281Z",
     "start_time": "2020-10-08T01:47:19.215064Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "# wine.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "wine = explanation.to_float(wine)\n",
    "\n",
    "model_file_name = 'serialized_model/RF_wine2.pkl'\n",
    "model = serializer.load_model(model_file_name)\n",
    "\n",
    "dataset = wine.copy(deep = True)\n",
    "target_names = np.array(['ruim', 'bom'])\n",
    "\n",
    "folder = 'serialized_explanation/'\n",
    "model_dataset = model_file_name.replace('serialized_model/','').replace('.pkl', '').replace('_', '#')\n",
    "\n",
    "for sample in wine_sample:\n",
    "    instance_index = sample\n",
    "    num_features = dataset.columns.size - 1 #removing the target\n",
    "\n",
    "    output_file = \"\"\"{0}{1}#instance:{2}#num_features:{3}.html\"\"\".format(folder, \n",
    "                                                                          model_dataset, \n",
    "                                                                          instance_index, \n",
    "                                                                          num_features)\n",
    "\n",
    "    explanation.explain_it(model,\n",
    "                           dataset,\n",
    "                           target_names,\n",
    "                           num_features,\n",
    "                           instance_index,\n",
    "                           output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T01:47:23.152564Z",
     "start_time": "2020-10-08T01:47:21.494046Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "# diabetes.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "diabetes = explanation.to_float(diabetes)\n",
    "\n",
    "model_file_name = 'serialized_model/RF_diabetes2.pkl'\n",
    "model = serializer.load_model(model_file_name)\n",
    "\n",
    "dataset = diabetes.copy(deep = True)\n",
    "target_names = np.array(['saud√°vel', 'doente'])\n",
    "\n",
    "folder = 'serialized_explanation/'\n",
    "model_dataset = model_file_name.replace('serialized_model/','').replace('.pkl', '').replace('_', '#')\n",
    "\n",
    "for sample in diabetes_sample:\n",
    "    instance_index = sample\n",
    "    num_features = dataset.columns.size - 1 #removing the target\n",
    "\n",
    "    output_file = \"\"\"{0}{1}#instance:{2}#num_features:{3}.html\"\"\".format(folder, \n",
    "                                                                          model_dataset, \n",
    "                                                                          instance_index, \n",
    "                                                                          num_features)\n",
    "\n",
    "    explanation.explain_it(model,\n",
    "                           dataset,\n",
    "                           target_names,\n",
    "                           num_features,\n",
    "                           instance_index,\n",
    "                           output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T01:47:24.644630Z",
     "start_time": "2020-10-08T01:47:23.154207Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "heart = explanation.to_float(heart)\n",
    "\n",
    "model_file_name = 'serialized_model/NaiveBayes_heart.pkl'\n",
    "model = serializer.load_model(model_file_name)\n",
    "\n",
    "dataset = heart.copy(deep = True)\n",
    "target_names = np.array(['saud√°vel', 'doente'])\n",
    "\n",
    "folder = 'serialized_explanation/'\n",
    "model_dataset = model_file_name.replace('serialized_model/','').replace('.pkl', '').replace('_', '#')\n",
    "\n",
    "for sample in heart_sample:\n",
    "    instance_index = sample\n",
    "    num_features = dataset.columns.size - 1 #removing the target\n",
    "\n",
    "    output_file = \"\"\"{0}{1}#instance:{2}#num_features:{3}.html\"\"\".format(folder, \n",
    "                                                                          model_dataset, \n",
    "                                                                          instance_index, \n",
    "                                                                          num_features)\n",
    "\n",
    "    explanation.explain_it(model,\n",
    "                           dataset,\n",
    "                           target_names,\n",
    "                           num_features,\n",
    "                           instance_index,\n",
    "                           output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T01:47:26.169922Z",
     "start_time": "2020-10-08T01:47:24.647054Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "# wine.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "wine = explanation.to_float(wine)\n",
    "\n",
    "model_file_name = 'serialized_model/NaiveBayes_wine2.pkl'\n",
    "model = serializer.load_model(model_file_name)\n",
    "\n",
    "dataset = wine.copy(deep = True)\n",
    "target_names = np.array(['ruim', 'bom'])\n",
    "\n",
    "folder = 'serialized_explanation/'\n",
    "model_dataset = model_file_name.replace('serialized_model/','').replace('.pkl', '').replace('_', '#')\n",
    "\n",
    "for sample in wine_sample:\n",
    "    instance_index = sample\n",
    "    num_features = dataset.columns.size - 1 #removing the target\n",
    "\n",
    "    output_file = \"\"\"{0}{1}#instance:{2}#num_features:{3}.html\"\"\".format(folder, \n",
    "                                                                          model_dataset, \n",
    "                                                                          instance_index, \n",
    "                                                                          num_features)\n",
    "\n",
    "    explanation.explain_it(model,\n",
    "                           dataset,\n",
    "                           target_names,\n",
    "                           num_features,\n",
    "                           instance_index,\n",
    "                           output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T01:47:27.349998Z",
     "start_time": "2020-10-08T01:47:26.172815Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "# diabetes.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "diabetes = explanation.to_float(diabetes)\n",
    "\n",
    "model_file_name = 'serialized_model/NaiveBayes_diabetes2.pkl'\n",
    "model = serializer.load_model(model_file_name)\n",
    "\n",
    "dataset = diabetes.copy(deep = True)\n",
    "target_names = np.array(['saud√°vel', 'doente'])\n",
    "\n",
    "folder = 'serialized_explanation/'\n",
    "model_dataset = model_file_name.replace('serialized_model/','').replace('.pkl', '').replace('_', '#')\n",
    "\n",
    "for sample in diabetes_sample:\n",
    "    instance_index = sample\n",
    "    num_features = dataset.columns.size - 1 #removing the target\n",
    "\n",
    "    output_file = \"\"\"{0}{1}#instance:{2}#num_features:{3}.html\"\"\".format(folder, \n",
    "                                                                          model_dataset, \n",
    "                                                                          instance_index, \n",
    "                                                                          num_features)\n",
    "\n",
    "    explanation.explain_it(model,\n",
    "                           dataset,\n",
    "                           target_names,\n",
    "                           num_features,\n",
    "                           instance_index,\n",
    "                           output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T01:47:29.204141Z",
     "start_time": "2020-10-08T01:47:27.352025Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "heart = explanation.to_float(heart)\n",
    "\n",
    "model_file_name = 'serialized_model/DT_heart.pkl'\n",
    "model = serializer.load_model(model_file_name)\n",
    "\n",
    "dataset = heart.copy(deep = True)\n",
    "target_names = np.array(['saud√°vel', 'doente'])\n",
    "\n",
    "folder = 'serialized_explanation/'\n",
    "model_dataset = model_file_name.replace('serialized_model/','').replace('.pkl', '').replace('_', '#')\n",
    "\n",
    "for sample in heart_sample:\n",
    "    instance_index = sample\n",
    "    num_features = dataset.columns.size - 1 #removing the target\n",
    "\n",
    "    output_file = \"\"\"{0}{1}#instance:{2}#num_features:{3}.html\"\"\".format(folder, \n",
    "                                                                          model_dataset, \n",
    "                                                                          instance_index, \n",
    "                                                                          num_features)\n",
    "\n",
    "    explanation.explain_it(model,\n",
    "                           dataset,\n",
    "                           target_names,\n",
    "                           num_features,\n",
    "                           instance_index,\n",
    "                           output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T01:47:31.170548Z",
     "start_time": "2020-10-08T01:47:29.206230Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "# wine.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "wine = explanation.to_float(wine)\n",
    "\n",
    "model_file_name = 'serialized_model/DT_wine2.pkl'\n",
    "model = serializer.load_model(model_file_name)\n",
    "\n",
    "dataset = wine.copy(deep = True)\n",
    "target_names = np.array(['ruim', 'bom'])\n",
    "\n",
    "folder = 'serialized_explanation/'\n",
    "model_dataset = model_file_name.replace('serialized_model/','').replace('.pkl', '').replace('_', '#')\n",
    "\n",
    "for sample in wine_sample:\n",
    "    instance_index = sample\n",
    "    num_features = dataset.columns.size - 1 #removing the target\n",
    "\n",
    "    output_file = \"\"\"{0}{1}#instance:{2}#num_features:{3}.html\"\"\".format(folder, \n",
    "                                                                          model_dataset, \n",
    "                                                                          instance_index, \n",
    "                                                                          num_features)\n",
    "\n",
    "    explanation.explain_it(model,\n",
    "                           dataset,\n",
    "                           target_names,\n",
    "                           num_features,\n",
    "                           instance_index,\n",
    "                           output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T01:47:32.670401Z",
     "start_time": "2020-10-08T01:47:31.173212Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "# diabetes.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "diabetes = explanation.to_float(diabetes)\n",
    "\n",
    "model_file_name = 'serialized_model/DT_diabetes2.pkl'\n",
    "model = serializer.load_model(model_file_name)\n",
    "\n",
    "dataset = diabetes.copy(deep = True)\n",
    "target_names = np.array(['saud√°vel', 'doente'])\n",
    "\n",
    "folder = 'serialized_explanation/'\n",
    "model_dataset = model_file_name.replace('serialized_model/','').replace('.pkl', '').replace('_', '#')\n",
    "\n",
    "for sample in diabetes_sample:\n",
    "    instance_index = sample\n",
    "    num_features = dataset.columns.size - 1 #removing the target\n",
    "\n",
    "    output_file = \"\"\"{0}{1}#instance:{2}#num_features:{3}.html\"\"\".format(folder, \n",
    "                                                                          model_dataset, \n",
    "                                                                          instance_index, \n",
    "                                                                          num_features)\n",
    "\n",
    "    explanation.explain_it(model,\n",
    "                           dataset,\n",
    "                           target_names,\n",
    "                           num_features,\n",
    "                           instance_index,\n",
    "                           output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T22:37:09.714067Z",
     "start_time": "2020-10-08T22:36:53.933680Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "heart = explanation.to_float(heart)\n",
    "\n",
    "# model_file_name = 'serialized_model/KNN_heart.pkl'\n",
    "model_file_name = 'serialized_model/KNN_heart.pkl'\n",
    "model = serializer.load_model(model_file_name)\n",
    "\n",
    "dataset = heart.copy(deep = True)\n",
    "target_names = np.array(['saud√°vel', 'doente'])\n",
    "\n",
    "folder = 'serialized_explanation/'\n",
    "model_dataset = model_file_name.replace('serialized_model/','').replace('.pkl', '').replace('_', '#')\n",
    "\n",
    "for sample in heart_sample:\n",
    "    instance_index = sample\n",
    "    num_features = dataset.columns.size - 1 #removing the target\n",
    "\n",
    "    output_file = \"\"\"{0}{1}#instance:{2}#num_features:{3}.html\"\"\".format(folder, \n",
    "                                                                          model_dataset, \n",
    "                                                                          instance_index, \n",
    "                                                                          num_features)\n",
    "\n",
    "    explanation.explain_it(model,\n",
    "                           dataset,\n",
    "                           target_names,\n",
    "                           num_features,\n",
    "                           instance_index,\n",
    "                           output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T01:47:33.300268Z",
     "start_time": "2020-10-08T01:47:08.963Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "# wine.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "wine = explanation.to_float(wine)\n",
    "\n",
    "model_file_name = 'serialized_model/KNN_wine2.pkl'\n",
    "model = serializer.load_model(model_file_name)\n",
    "\n",
    "dataset = wine.copy(deep = True)\n",
    "target_names = np.array(['ruim', 'bom'])\n",
    "\n",
    "folder = 'serialized_explanation/'\n",
    "model_dataset = model_file_name.replace('serialized_model/','').replace('.pkl', '').replace('_', '#')\n",
    "\n",
    "for sample in wine_sample:\n",
    "    instance_index = sample\n",
    "    num_features = dataset.columns.size - 1 #removing the target\n",
    "\n",
    "    output_file = \"\"\"{0}{1}#instance:{2}#num_features:{3}.html\"\"\".format(folder, \n",
    "                                                                          model_dataset, \n",
    "                                                                          instance_index, \n",
    "                                                                          num_features)\n",
    "\n",
    "    explanation.explain_it(model,\n",
    "                           dataset,\n",
    "                           target_names,\n",
    "                           num_features,\n",
    "                           instance_index,\n",
    "                           output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T01:47:33.301767Z",
     "start_time": "2020-10-08T01:47:08.969Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "# diabetes.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "diabetes = explanation.to_float(diabetes)\n",
    "\n",
    "model_file_name = 'serialized_model/KNN_diabetes2.pkl'\n",
    "model = serializer.load_model(model_file_name)\n",
    "\n",
    "dataset = diabetes.copy(deep = True)\n",
    "target_names = np.array(['saud√°vel', 'doente'])\n",
    "\n",
    "folder = 'serialized_explanation/'\n",
    "model_dataset = model_file_name.replace('serialized_model/','').replace('.pkl', '').replace('_', '#')\n",
    "\n",
    "for sample in diabetes_sample:\n",
    "    instance_index = sample\n",
    "    num_features = dataset.columns.size - 1 #removing the target\n",
    "\n",
    "    output_file = \"\"\"{0}{1}#instance:{2}#num_features:{3}.html\"\"\".format(folder, \n",
    "                                                                          model_dataset, \n",
    "                                                                          instance_index, \n",
    "                                                                          num_features)\n",
    "\n",
    "    explanation.explain_it(model,\n",
    "                           dataset,\n",
    "                           target_names,\n",
    "                           num_features,\n",
    "                           instance_index,\n",
    "                           output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T01:51:32.604902Z",
     "start_time": "2020-10-08T01:51:30.851975Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "heart = explanation.to_float(heart)\n",
    "\n",
    "model_file_name = 'serialized_model/GaussianProcessClassifier_heart.pkl'\n",
    "model = serializer.load_model(model_file_name)\n",
    "\n",
    "dataset = heart.copy(deep = True)\n",
    "target_names = np.array(['saud√°vel', 'doente'])\n",
    "\n",
    "folder = 'serialized_explanation/'\n",
    "model_dataset = model_file_name.replace('serialized_model/','').replace('.pkl', '').replace('_', '#')\n",
    "\n",
    "for sample in heart_sample:\n",
    "    instance_index = sample\n",
    "    num_features = dataset.columns.size - 1 #removing the target\n",
    "\n",
    "    output_file = \"\"\"{0}{1}#instance:{2}#num_features:{3}.html\"\"\".format(folder, \n",
    "                                                                          model_dataset, \n",
    "                                                                          instance_index, \n",
    "                                                                          num_features)\n",
    "\n",
    "    explanation.explain_it(model,\n",
    "                           dataset,\n",
    "                           target_names,\n",
    "                           num_features,\n",
    "                           instance_index,\n",
    "                           output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T01:51:54.418718Z",
     "start_time": "2020-10-08T01:51:51.010405Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "# wine.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "wine = explanation.to_float(wine)\n",
    "\n",
    "model_file_name = 'serialized_model/GaussianProcessClassifier_wine2.pkl'\n",
    "model = serializer.load_model(model_file_name)\n",
    "\n",
    "dataset = wine.copy(deep = True)\n",
    "target_names = np.array(['ruim', 'bom'])\n",
    "\n",
    "folder = 'serialized_explanation/'\n",
    "model_dataset = model_file_name.replace('serialized_model/','').replace('.pkl', '').replace('_', '#')\n",
    "\n",
    "for sample in wine_sample:\n",
    "    instance_index = sample\n",
    "    num_features = dataset.columns.size - 1 #removing the target\n",
    "\n",
    "    output_file = \"\"\"{0}{1}#instance:{2}#num_features:{3}.html\"\"\".format(folder, \n",
    "                                                                          model_dataset, \n",
    "                                                                          instance_index, \n",
    "                                                                          num_features)\n",
    "\n",
    "    explanation.explain_it(model,\n",
    "                           dataset,\n",
    "                           target_names,\n",
    "                           num_features,\n",
    "                           instance_index,\n",
    "                           output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T01:51:58.056823Z",
     "start_time": "2020-10-08T01:51:56.294785Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "# diabetes.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "diabetes = explanation.to_float(diabetes)\n",
    "\n",
    "model_file_name = 'serialized_model/GaussianProcessClassifier_diabetes2.pkl'\n",
    "model = serializer.load_model(model_file_name)\n",
    "\n",
    "dataset = diabetes.copy(deep = True)\n",
    "target_names = np.array(['saud√°vel', 'doente'])\n",
    "\n",
    "folder = 'serialized_explanation/'\n",
    "model_dataset = model_file_name.replace('serialized_model/','').replace('.pkl', '').replace('_', '#')\n",
    "\n",
    "for sample in diabetes_sample:\n",
    "    instance_index = sample\n",
    "    num_features = dataset.columns.size - 1 #removing the target\n",
    "\n",
    "    output_file = \"\"\"{0}{1}#instance:{2}#num_features:{3}.html\"\"\".format(folder, \n",
    "                                                                          model_dataset, \n",
    "                                                                          instance_index, \n",
    "                                                                          num_features)\n",
    "\n",
    "    explanation.explain_it(model,\n",
    "                           dataset,\n",
    "                           target_names,\n",
    "                           num_features,\n",
    "                           instance_index,\n",
    "                           output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T02:24:37.129107Z",
     "start_time": "2020-10-09T02:24:19.325229Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "heart = pd.read_csv('data/datasets_33180_43520_heart.csv', sep = ',')\n",
    "heart = explanation.to_float(heart)\n",
    "\n",
    "model_file_name = 'serialized_model/svm_heart.pkl'\n",
    "model = serializer.load_model(model_file_name)\n",
    "\n",
    "dataset = heart.copy(deep = True)\n",
    "target_names = np.array(['saud√°vel', 'doente'])\n",
    "\n",
    "folder = 'serialized_explanation/'\n",
    "model_dataset = model_file_name.replace('serialized_model/','').replace('.pkl', '').replace('_', '#')\n",
    "\n",
    "for sample in heart_sample:\n",
    "    instance_index = sample\n",
    "    num_features = dataset.columns.size - 1 #removing the target\n",
    "\n",
    "    output_file = \"\"\"{0}{1}#instance:{2}#num_features:{3}.html\"\"\".format(folder, \n",
    "                                                                          model_dataset, \n",
    "                                                                          instance_index, \n",
    "                                                                          num_features)\n",
    "\n",
    "    explanation.explain_it(model,\n",
    "                           dataset,\n",
    "                           target_names,\n",
    "                           num_features,\n",
    "                           instance_index,\n",
    "                           output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T11:13:32.731512Z",
     "start_time": "2020-10-08T11:13:32.182067Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wine = pd.read_csv('data/wine_limpo.csv', sep = ',')\n",
    "# wine.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "wine = explanation.to_float(wine)\n",
    "\n",
    "model_file_name = 'serialized_model/svm_wine2.pkl'\n",
    "model = serializer.load_model(model_file_name)\n",
    "\n",
    "dataset = wine.copy(deep = True)\n",
    "target_names = np.array(['ruim', 'bom'])\n",
    "\n",
    "folder = 'serialized_explanation/'\n",
    "model_dataset = model_file_name.replace('serialized_model/','').replace('.pkl', '').replace('_', '#')\n",
    "\n",
    "for sample in wine_sample:\n",
    "    instance_index = sample\n",
    "    num_features = dataset.columns.size - 1 #removing the target\n",
    "\n",
    "    output_file = \"\"\"{0}{1}#instance:{2}#num_features:{3}.html\"\"\".format(folder, \n",
    "                                                                          model_dataset, \n",
    "                                                                          instance_index, \n",
    "                                                                          num_features)\n",
    "\n",
    "    explanation.explain_it(model,\n",
    "                           dataset,\n",
    "                           target_names,\n",
    "                           num_features,\n",
    "                           instance_index,\n",
    "                           output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T01:49:46.948435Z",
     "start_time": "2020-10-08T01:49:46.702844Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import sys\n",
    "sys.path.append('./ml_helper')\n",
    "import ml_helper_train_model as model_train\n",
    "import ml_helper_serialize_model as serializer\n",
    "sys.path.append('./explanation_helper')\n",
    "import expla_helper as explanation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes_limpo.csv', sep = ',')\n",
    "# diabetes.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "diabetes = explanation.to_float(diabetes)\n",
    "\n",
    "model_file_name = 'serialized_model/svm_diabetes2.pkl'\n",
    "model = serializer.load_model(model_file_name)\n",
    "\n",
    "dataset = diabetes.copy(deep = True)\n",
    "target_names = np.array(['saud√°vel', 'doente'])\n",
    "\n",
    "folder = 'serialized_explanation/'\n",
    "model_dataset = model_file_name.replace('serialized_model/','').replace('.pkl', '').replace('_', '#')\n",
    "\n",
    "for sample in diabetes_sample:\n",
    "    instance_index = sample\n",
    "    num_features = dataset.columns.size - 1 #removing the target\n",
    "\n",
    "    output_file = \"\"\"{0}{1}#instance:{2}#num_features:{3}.html\"\"\".format(folder, \n",
    "                                                                          model_dataset, \n",
    "                                                                          instance_index, \n",
    "                                                                          num_features)\n",
    "\n",
    "    explanation.explain_it(model,\n",
    "                           dataset,\n",
    "                           target_names,\n",
    "                           num_features,\n",
    "                           instance_index,\n",
    "                           output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(3.6.6 Down)",
   "language": "python",
   "name": "python366_down"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
